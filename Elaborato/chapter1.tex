\chapter{Algoritmi sequenziali}
Prima di avviarci nella teoria del calcolo parallelo è doverosa un'introduzione al calcolo sequenziale e, nello specifico, al concetto di algoritmo.\\
La definizione informale di un algoritmo è un concetto generalmente noto: un algoritmo è una sequenza finita di operazioni elementari (univoche e non ambigue) che, date in esecuzione a un agente, manipola diversi valori in input per per ottenerne degli altri in output. In altre parole un algoritmo definisce implicitamente una funzione da un dominio di definizione (input) a un codominio specifico (output) e tale che per ogni input appartenente al dominio esista sempre un output corrispondente. Detto ciò, se definiamo un algoritmo A, chiameremo $\mathrm{f}_{A}(x)$ la funzione che associa ad ogni \textit{x} del dominio la corrispondente uscita $\mathrm{f}_{A}(x)$. In questa definizione è racchiuso implicitamente il problema risolto dall'algoritmo.\\
Formalmente, dato un problema $\mathrm{f}: I \rightarrow S$, in cui \textit{I} rappresenta l'insieme delle varie istanze e \textit{S} l'insieme delle soluzioni, possiamo affermare che un algoritmo \textit{A} risolve tale problema se $\mathrm{f}_{A}(x) = \mathrm{f}(x)$ per ogni istanza \textit{x}.\\
È bene precisare che per ogni problema f possono esistere numerosi algoritmi che lo risolvono in maniera differente, e poiché l'utilizzo di un algoritmo comporta sempre l'utilizzo di un certo quantitativo di risorse (tempo di esecuzione, memoria, ecc.), il saper scegliere o costruire un algoritmo che le sappia gestire in maniera adeguata non è un particolare di poco conto. Un cattivo utilizzo delle risorse, nel peggiore dei casi, può rappresentare un vero e proprio ostacolo a livello di esecuzione, e per questo motivo è importante trovare un modo per valutare la bontà di un algoritmo. Un metodo largamente utilizzato per ottenere questa valutazione è quello di adottare un modello di calcolo preciso e di tradurre l'algoritmo in modo da poter essere interpretato dallo stesso.\\
Poiché la nostra analisi è orientata principalmente allo studio della complessità sequenziale, ci concentreremo su un comodo modello di calcolo, specializzato in questo campo: la macchina di Turing.
\section{Macchina di Turing Deterministica}
La macchina di Turing (MdT) è un modello ideale di calcolatore dalle meccaniche intuitive e semplici, solitamente usato più per l'analisi computazionale che per l'implementazione di calcolatori reali. Vista la sua semplicità, rappresenta uno dei modelli più utilizzati per identificare e studiare il calcolo sequenziale.\\
Informalmente una MdT è composta da un insieme di stati interni, in cui si può trovare la macchina (si definisce anche uno "stato iniziale", in cui si trova all'inizio dell'esecuzione, e un insieme di stati finali), un nastro di lunghezza infinita suddiviso in celle e una testina posizionata su una di esse, capace di leggere, scrivere o cancellare caratteri sul nastro. La macchina analizza il nastro una cella alla volta e in base al carattere letto e allo stato interno corrente esegue una "mossa", così composta:
\begin{itemize}
\item{la macchina cambia il proprio stato interno;}
\item{la macchina esegue un'operazione di scrittura o muove la testina di una cella a destra o sinistra.}
\end{itemize}
Se la sequenza di mosse eseguite è finita diciamo che la macchina si arresta sull'input considerato e diciamo che tale input è accettato se lo stato raggiunto nell'ultima configurazione è finale.\\
Formalmente, invece, possiamo vedere la MdT come una sestupla:
\begin{center}
{M = < Q, $\sum$, $\mathrm{q}_{0}$, B, $\delta$, F >\\}
\end{center}
In particolare:
\begin{itemize}
\item{Q è l'insieme degli stati interni;}
\item{$\sum$ è l'alfabeto con cui vengono espressi i dati sul nastro;}
\item{$\mathrm{q}_{0} \in Q$ è lo stato iniziale;}
\item{$B \in \sum$ è un simbolo particolare, detto simbolo vuoto o blank;}
\item{$\delta$ è la funzione di transizione definita come $\delta$: $Q \times \sum \rightarrow  Q \times \sum \times$ \{-1,1\};}
\item{$F \subseteq Q$ è  l'insieme di stati finali.}
\end{itemize}
Per ogni $q \in Q$ e ogni $a \in \sum$, la funzione $\delta(q, a)$ definisce una tripla (p, b, l), dove p rappresenta il nuovo stato, b il carattere scritto nella cella corrente e l il movimento che esegue la testina, rispettivamente a destra se l = -1, a sinistra se l = +1.\\
Una configurazione particolare della macchina M è composta dallo stato della macchina, dal contenuto del nastro e dalla posizione della testina. Il tutto è esprimibile come una stringa: $\alpha$q$\beta$, con $\alpha \in \sum^*$, $q \in Q$, $\beta \in \sum^+$. In questo caso $\alpha$ rappresenta la stringa a sinistra della testina, q lo stato corrente di M, mentre $\beta$ una stringa collocata a destra della testina, seguita da infiniti caratteri blank. Notiamo che allo stato iniziale la configurazione diventa la stringa $\mathrm{q}_{0} \beta$. In questo contesto definiamo un'altra operazione binaria sull'insieme delle configurazioni C, l'operazione $\vdash_{M}$, tale che per ogni $C1, C2 \in C$, vale che $C1 \vdash_{M} C2$ se e solo se C1 raggiunge C2 in una mossa. Più precisamente, data la configurazione $\alpha$q$\beta \in C$ allo scatto di una transizione $\delta(q, b) = (p, b, l)$ (supponiamo che $\beta = b\beta', \beta' \in \sum^*, b \in \sum$ ) distinguiamo due casi:\\
\begin{itemize}
\item{se l = +1 allora:}
\[\alpha qb \beta \vdash_{M} \left\{
  \begin{array}{lr}
    \alpha cp \beta' & : \beta' \neq \epsilon\\
    \alpha cpB & : \beta' = \epsilon
  \end{array}
\right.
\]
\item{se l = -1 e $\alpha \neq \epsilon$ allora, posto $\alpha = \alpha' a $, $\alpha' \in \sum^*, a \in \sum$:}
\[\alpha qb \beta \vdash_{M} \left\{
  \begin{array}{lr}
    \alpha' pa & : c = B, \beta' = \epsilon\\
    \alpha pac\beta' & : altrimenti
  \end{array}
\right.
\]
\end{itemize}
Osserviamo che se $\delta(q,b)$ non è definito , oppure $l = -1$ e $\alpha = \epsilon$, allora non esiste una configurazione $C2 \in C$ tale che $\alpha q \beta \vdash_{M} C$. In questo caso diciamo che q e una configurazione di arresto per M. Senza perdita di generalità possiamo supporre che ogni configurazione accettante sia una configurazione di arresto.\\
Un insieme finito ${C}_{i}$ con \textit{i = {1,..,m}}, di configurazioni di M è una computazione di M su input $w \in \sum$, se ${C}_{0} = {C}_{0}(w)$, ${C}_{i-1} \vdash_{M} {C}_{i} \forall i = 1,2,..,m$ e ${C}_{m}$ è di arresto. Se ${C}_{m}$ è anche accettante, diciamo che M accetta l'input w. Viceversa, se M non termina, possiamo dire che l'input w genera una computazione definita da infinite configurazioni.\\
Inoltre, se M si arresta su ogni input $x \in \sum^*$, diciamo che M risolve il problema di decisione $<\sum^*, q>$ dove, $\forall x \in \sum^*$:
\[q(x) =\left\{
  \begin{array}{lr}
    1 & \ se \ M  \ accetta \ x \\
    0 & altrimenti
  \end{array}
\right.
\]\\
La MdT ha avuto un ruolo fondamentale nell'informatica teorica: poiché è matematicamente dimostrato che per qualsiasi modello di calcolo ragionevole esiste una macchina di Turing associata (tesi di Church-Turing), questo ha reso possibile definire uno standard nell'analisi computazionale degli algoritmi e una loro classificazione dal punto di vista risolutivo.
\section{Complessità sequenziale}
Quando analizziamo un algoritmo dobbiamo tenere in considerazione due caratteristiche: il fatto che risolva correttamente il problema che gli viene chiesto di risolvere (correttezza) e quante risorse impiega per essere eseguito (complessità). Le risorse utilizzate da un algoritmo sono essenzialmente il tempo di calcolo e la memoria utilizzata, che possiamo esprimere come funzioni a valori interi positivi. Nello specifico un algoritmo A su input \textit{x} viene rappresentata da una funzione ${T}_{A}(x)$ per il tempo e da ${M}_{A}(x)$ per lo spazio.\\
Cercare di dare una definizione formale di queste misure può risultare problematico, soprattutto perché la variabile \textit{x} può assumere tutti i valori in input. Per questo motivo si cerca di raggruppare le varie istanze del problema a seconda della loro dimensione, definendo una funzione che associa a ogni ingresso un numero naturale che rappresenta la quantità di informazione contenuta. Per fare un esempio, la dimensione di un numero naturale \textit{n} è $\lfloor \log(n) \rfloor +1$, ovvero la sua lunghezza in codice binario, mentre un array di $n$ elementi ha dimensione $n$.\\
Tuttavia classificare le varie istanze mediante la loro dimensione non è sufficiente: è possibile che a input diversi \textit{x $\neq$ y}, ma aventi la stessa dimensione ($|x| = |y|$), si possa ottenere 
${T}_{A}(x) \neq {T}_{A}(x')$. Questo fatto è ancora più evidente nel caso pratico: l'esecuzione di un programma su un calcolatore dipende sempre da numerosi fattori come la macchina usata, il linguaggio, il compilatore, ecc.\\
Per ovviare a questo problema si definiscono le funzioni in modo da ottenere una stima \textbf{assoluta} di quella che è la complessità di un algoritmo. Ad esempio tra le varie stime ottenibili per il tempo ${T}_{A}(x)$ vengono solitamente considerati i seguenti casi:
\begin{itemize}
\item{caso peggiore: ${T}_{A}^w: \mathbb{N} \rightarrow \mathbb{N}$, ${T}_{A}^w(n) = \max({T}_{A}(x)\ t.c.\ |x| = n)$};
\item{caso migliore: ${T}_{A}^b: \mathbb{N} \rightarrow \mathbb{N}$, ${T}_{A}^b(n) = \min({T}_{A}(x)\ t.c.\ |x| = n)$};
\item{caso medio: ${T}_{A}^a: \mathbb{N} \rightarrow \mathbb{R}$ con $I_n = $ numero di istanze $x \in I$ di dimensione n, ${T}_{A}^a(n) = \frac{\sum \nolimits_{|x| = n} {T}_{A}(x)}{I_n}$};
\end{itemize}
Prediligere una stima piuttosto che un'altra è una decisione puramente legata all'utilizzo dell'algoritmo. Dal punto di vista analitico, però, si tende a prediligere l'andamento nel caso peggiore, ovvero nel caso in cui l'input richiede il maggior numero di iterazioni per terminare, o nel caso medio, che analizza la computazione da un punto di vista statistico.\\
Presentiamo un esempio classico per capire come ottenere il tempo di calcolo: l'ordinamento di un array. Vogliamo ordinare un vettore $[x_1,..,x_n]$ di $n$ numeri in ordine crescente nel seguente modo:\\
\\
\textit{Per i = 1,..,n esegui iterativamente le seguenti operazioni\\
    - seleziona il minimo tra i valori $[x_i,..,x_n]$\\
    - scambialo con $x_i$}\\
\\
In questo caso l'algoritmo esegue $n + (n-1) + .. + 1 = \frac{n(n-1)}{2}$ passi per ottenere un vettore ordinato.\\
Nel modello della MdT, data una macchina M = <Q,$\sum$,$\mathrm{q}_{0}$,B,$\delta$,F> e un input definito da una stringa $w \in \sum^*$, definiamo con $T_M(w)$ come il massimo numero di mosse da effettuare per terminare l'esecuzione.\\ Ovviamente $T_M(w) = +\infty \leftrightarrow$ M non termina su $ w $.\\
Quindi possiamo definire una funzione $T_M(n)$ di stima del tempo di calcolo nel seguente modo:
\begin{center}
{$T_M(n) = \max(T_M(w) \ t.c.\ w \in \sum^* , |w| = n)$}
\end{center}
Inoltre, data $ f $ una funzione a valori reali positivi, diciamo che M esegue una computazione in tempo $f(n)$ se $T_M(n) \leq f(n) \ \forall n \in \mathbb{N}$.
\subsection{Analisi Asintotica della Complessità}
Abbiamo illustrato come avviene lo studio dei vari casi di computazione di un algoritmo. Tuttavia, per confrontare tra di loro algoritmi che risolvono lo stesso problema, così da scegliere il migliore disponibile, si ricorre a criteri di valutazione più specifici. Quello più utilizzato è il calcolo computazionale asintotico (solitamente riferito al caso medio o peggiore di un algoritmo).\\
Sostanzialmente si tratta di valutare la complessità di un algoritmo su input avente un entrata di dimensioni molto grandi, ovvero ponendo $n \rightarrow +\infty$. Ovviamente questo meccanismo vacilla se utilizziamo l'algoritmo per problemi relativamente piccoli, ma rilevare anche una piccola differenza nell’ordine di grandezza della complessità di due procedure può determinare enormi differenze in termini di prestazioni.\\
Proviamo, per esempio, a confrontare diversi algoritmi che risolvono lo stesso problema aventi complessità asintoticamente pari a: $n, \ n\log(n), \ n^2, \ 2^n$. Supponendo che ogni operazione venga eseguita in $1\mu s$ l'esecuzione richiederà un tempo di esecuzione pari a\footnote{Nella tabella s= secondi, h = ore, c = secoli.}
\\
\\
\label{my-label}
\begin{tabular}{|l|l|l|l|l|l|}
\hline
			& $n=10$     & $n=100$       	& $n=1000$      & $n=10000$  & $n=100000$  \\   \hline
$n$   		& $10\mu s$  & $0.1 ms$      	&  $1ms$      	& $10s$  	 & $0.1s$      \\	\hline
$n\log(n)$  & $23\mu s$  & $460.5 \mu s$    &  $6.9 ms$     & $92.1 ms$  & $1.15 s$    \\	\hline
$n^2$ 		& $0.1ms$    & $10ms$        	&  $1s$         & $100s$     & $2.7h$      \\	\hline
$2^n$		& $1ms$      & $ 10^{14} c$     &  $\infty$     & $\infty$   & $\infty$    \\   \hline
\end{tabular}
Notiamo che per problemi avente complessità lineare ($n \ o \ n\log(n)$) la computazione avvenga in tempo relativamente buono per problemi anche di grandi dimensioni. Al contrario algoritmi aventi complessità $n^k \ con \ k \geq 2 $ risultano convenienti solo per problemi contenuti, mentre andando su complessità esponenziali il problema esplode anche sulle piccole dimensioni. 
\subsection{Efficienza degli Algoritmi}
Mediante valutazioni precedenti si possono classificare la gran parte degli algoritmi realizzabili, distinguendoli mediante la loro complessità asintotica. Introduciamo così il concetto di \textbf{efficienza}: un algoritmo si dice efficiente quando la sua complessità è di \textbf{ordine polinomiale}, ovvero che vale $\mathcal{O}(n^k)$ con $k \geq 1$; un algoritmo si dice invece inefficiente quando la sua complessità è di \textbf{ordine superpolinomiale} (per esempio, $\mathcal{O}(n!)$ o $\mathcal{O}(k^n)$ con $k \geq 2$).\\
Va puntualizzato che non sempre è possibile creare un algoritmo efficiente (soprattutto nella MdT che abbiamo descritto). L'insieme dei problemi che è possibile risolvere a complessità polinomiale è detta classe P, nelle MdT deterministiche, e NP, nelle MdT non deterministiche. Non tratteremo nel dettaglio questi concetti, soprattutto perché sono ancora oggetto di dibattito\footnote{Il problema P = NP? legato ai problemi NP-completi è uno dei problemi irrisolti più famosi della matematica odierna.}, ma è bene specificare che esistono strumenti per stabilire se un problema è risolvibile o no in modo efficiente.\\
Un ultimo concetto da tener presente nella complessità algoritmi è il principio di \textbf{ottimalità}: dato un problema risolto con complessità peri a $f(n)$, diciamo che l'algoritmo che lo risolve è \textbf{ottimo} se qualunque altro algoritmo che lo risolve ha complessità $\mathcal{O}(f(n))$.
\chapter{Esempi}
Di seguito verranno presentati alcuni esempi di algoritmi sequenziali, molti dei quali verranno implementati a livello di codice alla fine dell'elaborato.
\section{Ordinamento}
Quello dell'ordinamento di un insieme di oggetti confrontabili è uno degli problemi tipici del calcolo algoritmico. Ne esistono di diversi tipi, il che lo rende un esempio perfetto per confrontare le varie alternative.\\
Prendiamo ad esempio due algoritmi piuttosto comuni in questo campo: quicksort\footnote{In linguaggio naturale: preso un elemento \textit{x} in una lista, se ne creano due: quella degli elementi minori di \textit{x} e quella degli elementi maggiori. Si richiama poi l'algoritmo sulle nuove liste, dopodiché si uniscono i risultati aggiungendo \textit{x} in mezzo agli stessi.} e mergesort\footnote{In linguaggio naturale: è il tipico algoritmo divide-et-impera; una lista avente uno o nessun elemento è ordinata, altrimenti si divide la lista in input in due e si esegue mergesort su entrambe; alla fine si estrae dalle due liste (ordinate) il minore tra i valori in testa, fino ad esaurire tutti gli elementi presenti.}. In questo caso, ad esempio i vari casi di esecuzione cambiano:
\begin{itemize}
\item{caso migliore:  $\mathcal {O}(n \log {}n)$ per quicksort e  $\mathcal {O}(n \log {}n)$ per mergesort;}
\item{caso peggiore:  $\mathcal {O}(n^2)$ per quicksort e  $\mathcal {O}(n \log {}n)$ per mergesort;}
\item{caso medio:  $\mathcal {O}(n \log {}n)$ per quicksort e  $\mathcal {O}(n \log {}n)$ per mergesort;}
\end{itemize}
\subsubsection{Pseudocodice}
\begin{verbatim}
Quicksort(L = [a1,...,an])
    if(n <= 1) then
        return L
    else
        scegli un elemento "p" in L
	    calcola la lista "left" di elementi minori di p
	    calcola la lista "right" di elementi maggiori di p
	    left = Quicksort(left)
	    right = Quicksort(right)
	    return left : [p] : right


Mergesort(L = [a1,..,an])
    if(n <= 1) then
        return L
    else
        dividi la lista L a metà, creando le liste "left" e "right" 
        left = Mergesort(left)
        right = Mergesort(right)
        return merge(left, right)
        
merge(left, right)
    if(left = []) return right
    else if(right = []) return left
    else
        h1 = head(left)
        h2 = head(right)
        if (h1 < h2) then
            t = tail(left)
            return [h1] : merge(t, right)
        else
            t = tail(right)
            return [h2] : merge(left, t)
\end{verbatim}
\section{Algebra Lineare}
Facciamo degli esempi riguardanti le operazioni tra matrici:
\begin{itemize}
\item{prodotto tra matrici}
\item{calcolo del determinante}
\end{itemize}
Nel primo caso il prodotto di matrici è un operazione direttamente proporzionale alle dimensioni degli operandi. In caso di prodotto di una matrice MxN con una MxP sarà necessario un algoritmo di complessità asintotica  $\mathcal {O}(N*M*P)$.
\subsubsection{Pseudocodice}
\begin{verbatim}
Prodotto(A = matrice MxN, B = matrice NxP)
	C = matrice MxP di zeri
    for (i from 1 to M)
        for (j from 1 to P)
            for (k from 1 to N)
                c_ij = c_ij + (a_ik * b_kj)
            end for
        end for
    end for
    return C
\end{verbatim}

\section{Grafi}
